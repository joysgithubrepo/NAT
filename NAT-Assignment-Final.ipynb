{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import PySwarms\n",
    "\n",
    "import pyswarms as ps\n",
    "from pyswarms.utils.plotters import (plot_cost_history, plot_contour, plot_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data-frame\n",
    "# Add two more additional columns for sin functions\n",
    "\n",
    "ds = pd.read_csv(\"two_spirals.dat\")\n",
    "ds[\"SINX1\"] = np.sin(ds[\"X1\"])\n",
    "ds[\"SINX2\"] = np.sin(ds[\"X2\"])\n",
    "\n",
    "# Split the dataset in train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(ds[[\"X1\", \"X2\", \"SINX1\", \"SINX2\"]], ds[\"Y\"], test_size=0.50)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(ds[[\"X1\", \"X2\"]], ds[\"Y\"], test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the features as X and the labels as y\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the neural network architecture\n",
    "\n",
    "n_inputs = 4\n",
    "n_hidden1 = 6\n",
    "n_hidden2 = 6\n",
    "n_classes = 2\n",
    "num_samples = len(X_train)\n",
    "\n",
    "# Set the swarm parameters\n",
    "\n",
    "dimensions = n_inputs*n_hidden1 + n_hidden1 + n_hidden1*n_hidden2 + n_hidden2 + n_hidden2*n_classes + n_classes\n",
    "\n",
    "n_particles = 100\n",
    "n_iters = 2000\n",
    "# d_options = {'c1': 0.5, 'c2': 0.9, 'w': 0.9}\n",
    "d_options = {'c1': 0.5, 'c2': 0.6, 'w': 0.9}\n",
    "\n",
    "# Create bounds\n",
    "# max_bound = 5.12 * np.ones(2)\n",
    "# min_bound = - max_bound\n",
    "# bounds = (min_bound, max_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "\n",
    "def logits_function(params, X):\n",
    "\n",
    "    \"\"\" Calculate roll-back the weights and biases\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    p: np.ndarray\n",
    "        The dimensions should include an unrolled version of the\n",
    "        weights and biases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of logits for layer 3\n",
    "\n",
    "    \"\"\"\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = params[0:n_inputs*n_hidden1].reshape((n_inputs,n_hidden1))\n",
    "    b1 = params[n_inputs*n_hidden1:n_inputs*n_hidden1 + n_hidden1].reshape((n_hidden1,))\n",
    "    W2 = params[n_inputs*n_hidden1 + n_hidden1:n_inputs*n_hidden1 + n_hidden1 + n_hidden1*n_hidden2].reshape((n_hidden1,n_hidden2))\n",
    "    b2 = params[n_inputs*n_hidden1 + n_hidden1 + n_hidden1*n_hidden2:n_inputs*n_hidden1 + n_hidden1 + n_hidden1*n_hidden2 + n_hidden2].reshape((n_hidden2,))\n",
    "    W3 = params[n_inputs*n_hidden1 + n_hidden1 + n_hidden1*n_hidden2 + n_hidden2:n_inputs*n_hidden1 + n_hidden1 + n_hidden1*n_hidden2 + n_hidden2 + n_hidden2*n_classes].reshape((n_hidden2,n_classes))\n",
    "    b3 = params[n_inputs*n_hidden1 + n_hidden1 + n_hidden1*n_hidden2 + n_hidden2 + n_hidden2*n_classes:n_inputs*n_hidden1 + n_hidden1 + n_hidden1*n_hidden2 + n_hidden2 + n_hidden2*n_classes + n_classes].reshape((n_classes,))   \n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
    "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    a2 = np.tanh(z2)     # Activation in Layer 2\n",
    "    z3 = a2.dot(W3) + b3 # Pre-activation in Layer 3\n",
    "    logits = z3          # Logits for Layer 3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "\n",
    "def forward_prop(params):\n",
    "\n",
    "    \"\"\"Forward propagation as objective function\n",
    "\n",
    "    This computes for the forward propagation of the neural network, as\n",
    "    well as the loss.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    params: np.ndarray\n",
    "        The dimensions should include an unrolled version of the\n",
    "        weights and biases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The computed negative log-likelihood loss given the parameters\n",
    "    \"\"\"\n",
    "\n",
    "    logits = logits_function(params, X_train)\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "\n",
    "    corect_logprobs = -np.log(probs[range(num_samples), y_train])\n",
    "    loss = np.sum(corect_logprobs) / num_samples\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to forward propagate through the entire swarm population\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Higher-level method to do forward_prop in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call instance of PSO\n",
    "# dimensions = n_inputs*n_hidden1 + n_hidden1 + n_hidden1*n_hidden2 + n_hidden2 + n_hidden2*n_classes + n_classes\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=n_particles, dimensions=dimensions, options=d_options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_history(cost_history=optimizer.cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pos, X):\n",
    "\n",
    "    \"\"\"\n",
    "    Use the trained weights to perform class predictions.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    pos: numpy.ndarray\n",
    "        Position matrix found by the swarm. Will be rolled\n",
    "        into weights and biases.\n",
    "    \"\"\"\n",
    "    logits = logits_function(pos, X)\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(pos, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
